{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98e62acc-32ab-4421-810b-84e02c0f8697",
   "metadata": {},
   "source": [
    "# Annotate and filter substitutions in early sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7900fdd5-c501-44a0-b942-057dc4f45211",
   "metadata": {},
   "source": [
    "Import Python modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a81f14-40b9-4645-b199-41c075d5f31e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "import altair as alt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from ruamel.yaml import YAML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce76389-d081-48a8-831c-6b2888650708",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-01T15:40:49.124863Z",
     "iopub.status.busy": "2021-06-01T15:40:49.124379Z",
     "iopub.status.idle": "2021-06-01T15:40:49.132681Z",
     "shell.execute_reply": "2021-06-01T15:40:49.131181Z",
     "shell.execute_reply.started": "2021-06-01T15:40:49.124817Z"
    }
   },
   "source": [
    "Get variables from `snakemake`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd67dcd-fd8e-4e3d-a1d2-6c57ab53c07e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "comparator_map_file = snakemake.input.comparator_map\n",
    "subs_csv = snakemake.input.subs_csv\n",
    "max_date = pd.to_datetime(snakemake.params.max_date)\n",
    "min_coverage = snakemake.params.min_coverage\n",
    "max_subs = snakemake.params.max_subs\n",
    "max_ambiguous = snakemake.params.max_ambiguous\n",
    "filter_runs = snakemake.params.filter_runs\n",
    "who_china_report_cases_yaml = snakemake.input.who_china_report_cases_yaml\n",
    "who_china_report_last_date = pd.to_datetime(snakemake.params.who_china_report_last_date)\n",
    "early_seqs_to_exclude_yaml = snakemake.input.early_seqs_to_exclude_yaml\n",
    "comparators = snakemake.params.comparators\n",
    "output_csv = snakemake.output.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d4eee3-0a07-4a23-954b-2e6903894b86",
   "metadata": {},
   "source": [
    "## Read data\n",
    "Read comparator map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cc9c3e-abab-451b-8b93-757ad1d5f9a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "comparator_map = pd.read_csv(comparator_map_file)\n",
    "\n",
    "assert set(comparators).issubset(comparator_map.columns)\n",
    "\n",
    "comparator_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1b7cbc-c7ec-4924-ac97-258fff1d4a61",
   "metadata": {},
   "source": [
    "Get set of mutations for each comparator getting **only** mismatch mutations to valid nucleotides:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4468c1-94c5-49bf-9c7a-9e7a0a73698b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "comparator_muts = {}\n",
    "valid_nts = ['A', 'C', 'G', 'T']\n",
    "for comparator in comparators:\n",
    "    comparator_muts[comparator] = set(\n",
    "        comparator_map\n",
    "        .assign(mutated=lambda x: x['reference'] != x[comparator],\n",
    "                mutation=lambda x: x['reference'] + x['site'].astype(str) + x[comparator])\n",
    "        .query('mutated')\n",
    "        .query('reference in @valid_nts')\n",
    "        .query(f\"{comparator} in @valid_nts\")\n",
    "        ['mutation']\n",
    "        )\n",
    "    print(f\"{comparator} has {len(comparator_muts[comparator])} mutations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f7f9ee-cc15-48ea-8ef8-74100c21b72d",
   "metadata": {},
   "source": [
    "Read substitutions and annotate which ones are in each comparator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ec4af1-689a-49a1-bbfb-fb993b1d2248",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "subs = (\n",
    "    pd.read_csv(subs_csv,  na_filter=False)\n",
    "    .assign(subs_list=lambda x: x['substitutions'].str.split(','),\n",
    "            date=lambda x: pd.to_datetime(x['date']),\n",
    "            frac_coverage=lambda x: 1 - x['n_gapped_to_ref'] / (\n",
    "                                        x['n_ident_to_ref'] +\n",
    "                                        x['n_ambiguous_to_ref'] +\n",
    "                                        x['n_subs_to_ref'] +\n",
    "                                        x['n_gapped_to_ref']\n",
    "                                        )\n",
    "            )\n",
    "    .sort_values('date')\n",
    "    .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "for comparator, muts in comparator_muts.items():\n",
    "    subs[f\"{comparator}_substitutions\"] = (subs\n",
    "                                           ['subs_list']\n",
    "                                           .map(lambda x: [xi for xi in x if xi in muts])\n",
    "                                           )\n",
    "    subs[f\"{comparator}_n_substitutions\"] = (subs\n",
    "                                             [f\"{comparator}_substitutions\"]\n",
    "                                             .map(len)\n",
    "                                             )\n",
    "    subs[f\"{comparator}_substitutions\"] = (subs\n",
    "                                           [f\"{comparator}_substitutions\"]\n",
    "                                           .map(lambda x: ','.join(x))\n",
    "                                           )\n",
    "subs = subs.drop(columns='subs_list')\n",
    "\n",
    "subs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fd2e24-6407-4b4c-bb5e-68b824e26b1e",
   "metadata": {},
   "source": [
    "## Filter sequences\n",
    "Filter sequences with insufficient coverage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b48641-c512-4d1d-be98-bbba7b200413",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Filtering sequences with <{min_coverage} alignment coverage\")\n",
    "\n",
    "subs['insufficient_coverage'] = subs['frac_coverage'] < min_coverage\n",
    "\n",
    "display(subs\n",
    "        .groupby('insufficient_coverage')\n",
    "        .aggregate(n_seqs=pd.NamedAgg('strain', 'count'))\n",
    "        )\n",
    "\n",
    "chart_frac_coverage = (\n",
    "    alt.Chart(subs)\n",
    "    .encode(x='frac_coverage',\n",
    "            y='frac_called_in_region_of_interest',\n",
    "            color='insufficient_coverage',\n",
    "            tooltip=['strain',\n",
    "                     'gisaid_epi_isl',\n",
    "                     'date',\n",
    "                     'n_subs_to_ref',\n",
    "                     'n_ident_to_ref',\n",
    "                     'substitutions'],\n",
    "            )\n",
    "    .mark_point(filled=True,\n",
    "                opacity=0.2,\n",
    "                )\n",
    "    )\n",
    "\n",
    "subs = (subs\n",
    "        .query('not insufficient_coverage')\n",
    "        .drop(columns='insufficient_coverage')\n",
    "        )\n",
    "\n",
    "chart_frac_coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6609ce9a-17fc-4c9a-9374-304b591165c3",
   "metadata": {},
   "source": [
    "Filter sequences with excess substitutions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf98377-50fc-4a76-a6d2-ff23a947a475",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Filtering sequences with >{max_subs} substitutions to reference\")\n",
    "\n",
    "subs['excess_subs'] = subs['n_subs_to_ref'] >= max_subs\n",
    "\n",
    "display(subs\n",
    "        .groupby('excess_subs')\n",
    "        .aggregate(n_seqs=pd.NamedAgg('strain', 'count'))\n",
    "        )\n",
    "\n",
    "chart_subs = (\n",
    "    alt.Chart(subs)\n",
    "    .encode(x='date',\n",
    "            y='n_subs_to_ref',\n",
    "            color='excess_subs',\n",
    "            tooltip=['strain',\n",
    "                     'gisaid_epi_isl',\n",
    "                     'date',\n",
    "                     'n_subs_to_ref',\n",
    "                     'n_ident_to_ref',\n",
    "                     'substitutions'],\n",
    "            )\n",
    "    .mark_point(filled=True,\n",
    "                opacity=0.2,\n",
    "                )\n",
    "    )\n",
    "\n",
    "subs = (subs\n",
    "        .query('not excess_subs')\n",
    "        .drop(columns='excess_subs')\n",
    "        )\n",
    "\n",
    "chart_subs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25c9e2d-8a2d-4cee-acb6-abf6d40b0bf2",
   "metadata": {},
   "source": [
    "Filter by number of ambiguous nucleotides:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee804fa-edc3-4fd9-beb0-ddb70b31df51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Filtering sequences with >{max_ambiguous} ambiguous nucleotides in alignment to reference\")\n",
    "\n",
    "subs['excess_ambiguous'] = subs['n_ambiguous_to_ref'] >= max_ambiguous\n",
    "\n",
    "display(subs\n",
    "        .groupby('excess_ambiguous')\n",
    "        .aggregate(n_seqs=pd.NamedAgg('strain', 'count'))\n",
    "        )\n",
    "\n",
    "\n",
    "chart_ambiguous = (\n",
    "    alt.Chart(subs)\n",
    "    .encode(x='date',\n",
    "            y='n_ambiguous_to_ref',\n",
    "            color='excess_ambiguous',\n",
    "            tooltip=['strain',\n",
    "                     'gisaid_epi_isl',\n",
    "                     'date',\n",
    "                     'n_subs_to_ref',\n",
    "                     'n_ident_to_ref',\n",
    "                     'n_ambiguous_to_ref',\n",
    "                     'substitutions'],\n",
    "            )\n",
    "    .mark_point(filled=True,\n",
    "                opacity=0.2,\n",
    "                )\n",
    "    )\n",
    "\n",
    "subs = (subs\n",
    "        .query('not excess_ambiguous')\n",
    "        .drop(columns='excess_ambiguous')\n",
    "        )\n",
    "\n",
    "chart_ambiguous"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d9dded-9364-416e-b9b6-1b8bca9669a5",
   "metadata": {},
   "source": [
    "Filter sequences with too early of date:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5aaee3e-ba8c-407b-9929-7ef36955ec20",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Filtering sequences collected after {max_date}\")\n",
    "subs['too_late_date'] = subs['date'] > max_date\n",
    "\n",
    "display(subs\n",
    "        .groupby('too_late_date')\n",
    "        .aggregate(n_seqs=pd.NamedAgg('strain', 'count'))\n",
    "        )\n",
    "\n",
    "subs = (subs\n",
    "        .query('not too_late_date')\n",
    "        .drop(columns='too_late_date')\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c9ff5f-5844-4ac9-8cfc-dd7beab2c6e1",
   "metadata": {},
   "source": [
    "Filter sequences with excessive mutations in a short run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7f094e-00ac-4f26-aa02-da919ec7b096",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_n_muts = filter_runs['n_muts']\n",
    "run_span = filter_runs['span']\n",
    "\n",
    "assert run_span > 1\n",
    "assert run_n_muts > 1\n",
    "\n",
    "print(f\"Filtering sequences with >= {run_n_muts} mutations within {run_span} nucleotides\")\n",
    "\n",
    "def pass_run_filter(sub_str):\n",
    "    sites = sorted([int(s[1: -1]) for s in sub_str.split(',') if s])\n",
    "    while len(sites) >= run_n_muts:\n",
    "        span = sites[run_n_muts - 1] - sites[0] \n",
    "        assert span > 0\n",
    "        if span <= run_span:\n",
    "            return False\n",
    "        sites = sites[1: ]\n",
    "    return True\n",
    "\n",
    "subs = subs.assign(pass_run_filter=lambda x: x['substitutions'].map(pass_run_filter))\n",
    "\n",
    "display(subs\n",
    "        .groupby('pass_run_filter')\n",
    "        .aggregate(n_seqs=pd.NamedAgg('strain', 'count'))\n",
    "        )\n",
    "\n",
    "subs = (subs\n",
    "        .query('pass_run_filter')\n",
    "        .drop(columns='pass_run_filter')\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5afa656-d77b-4b87-bbf6-68c10fbe4735",
   "metadata": {},
   "source": [
    "## Check sequences against WHO-China joint report\n",
    "Here we make sure that:\n",
    " 1. We find a sequence for every sample listed in WHO-China report.\n",
    " 2. When there are clearly multiple sequences from the same patient (based mostly on WHO-China report descriptions) collapse to just one to keep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6815beab-1417-4d2d-a8da-cd689374a01b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Examining early sequences isolated on or before {who_china_report_last_date}\\n\")\n",
    "\n",
    "with open(who_china_report_cases_yaml) as f:\n",
    "    who_china_report_cases = YAML(typ='safe').load(f)\n",
    "    \n",
    "subs_early = subs.query('date <= @who_china_report_last_date')\n",
    "assert subs_early['strain'].nunique() == len(subs_early)\n",
    "\n",
    "all_to_keep = []\n",
    "all_to_collapse = []\n",
    "\n",
    "for sample, sample_d in who_china_report_cases['pre_2020_seqs'].items():\n",
    "    date = pd.to_datetime(sample_d['date'])\n",
    "    \n",
    "    # get entries in subs matching the strains\n",
    "    sample_mask = subs['strain'].str.contains(sample_d['strain'][0], regex=False)\n",
    "    for strain in sample_d['strain'][1:]:\n",
    "        sample_mask = sample_mask | subs['strain'].str.contains(strain, regex=False)\n",
    "    strains_to_keep = []\n",
    "    strains_to_collapse = []\n",
    "    if 'collapse_to' in sample_d:\n",
    "        for strain in subs_early.loc[sample_mask].strain.tolist():\n",
    "            if any(keep in strain for keep in sample_d['collapse_to']):\n",
    "                strains_to_keep.append(strain)\n",
    "            else:\n",
    "                strains_to_collapse.append(strain)\n",
    "    else:\n",
    "        strains_to_keep = subs_early.loc[sample_mask].strain.tolist()\n",
    "    if not strains_to_keep:\n",
    "        raise ValueError(f\"no strains matching {sample}:\\n{sample_d}\")\n",
    "    print(f\"For {sample}\\n  Retaining:\\n    \" + '\\n    '.join(strains_to_keep))\n",
    "    if strains_to_collapse:\n",
    "        print(f\"  Collapsing:\\n    \" + '\\n    '.join(strains_to_collapse))\n",
    "    all_to_keep += strains_to_keep\n",
    "    all_to_collapse += strains_to_collapse\n",
    "    \n",
    "assert len(all_to_keep) == len(set(all_to_keep)), collections.Counter(all_to_keep)\n",
    "assert len(all_to_collapse) == len(set(all_to_collapse))\n",
    "\n",
    "print(f\"\\nKeeping the following {len(all_to_keep)} early sequences in WHO-China report:\")\n",
    "display(subs_early.query('strain in @all_to_keep').reset_index(drop=True))\n",
    "\n",
    "print(f\"\\nRemoving the following {len(all_to_collapse)} early sequences in WHO-China report \"\n",
    "      'as duplicates of other samples:')\n",
    "display(subs_early.query('strain in @all_to_collapse').reset_index(drop=True))\n",
    "\n",
    "not_in_report = subs_early.query('strain not in @all_to_collapse').query('strain not in @all_to_keep')\n",
    "print(f\"\\nAlso keeping the following {len(not_in_report)} early sequences not in the report:\")\n",
    "display(not_in_report.reset_index(drop=True))\n",
    "\n",
    "subs = subs.query('strain not in @all_to_collapse')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84a18d2-233f-42e4-a4d4-0b32ebd709e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-02T01:44:05.753956Z",
     "iopub.status.busy": "2021-06-02T01:44:05.753364Z",
     "iopub.status.idle": "2021-06-02T01:44:05.790314Z",
     "shell.execute_reply": "2021-06-02T01:44:05.789742Z",
     "shell.execute_reply.started": "2021-06-02T01:44:05.753905Z"
    },
    "tags": []
   },
   "source": [
    "## Remove sequences manually specified for exclusion\n",
    "Sequences identified as problematic in some way by manual inspection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b9e1ec-5813-42b7-9de2-7a672aff2179",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(early_seqs_to_exclude_yaml) as f:\n",
    "    early_seqs_to_exclude = YAML(typ='safe').load(f)\n",
    "\n",
    "gisaid_to_exclude = list(early_seqs_to_exclude['gisaid'])\n",
    "print(f\"Removing {len(gisaid_to_exclude)} GISAID IDs specified for manual removal\")\n",
    "\n",
    "assert len(gisaid_to_exclude) == len(set(gisaid_to_exclude))\n",
    "\n",
    "assert set(gisaid_to_exclude).issubset(subs['gisaid_epi_isl'])\n",
    "\n",
    "subs = subs.query('gisaid_epi_isl not in @gisaid_to_exclude')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e34663-041f-4007-9e0c-d733f1a16aeb",
   "metadata": {},
   "source": [
    "## Check for duplicated strains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ca7d16-c6ce-4d5f-8509-49c8ae2a20a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_strains = (\n",
    "    subs\n",
    "    .assign(n=lambda x: x.groupby('strain')['gisaid_epi_isl'].transform('count'))\n",
    "    .query('n > 1')\n",
    "    )\n",
    "\n",
    "if len(dup_strains):\n",
    "    raise ValueError('Duplicated strains:\\n' + str(dup_strains))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bee2540-833a-447f-a5ee-f98ed2150ce1",
   "metadata": {},
   "source": [
    "## Write annotated and filtered substitutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41cfd5e-8d2e-4372-82f4-ecd759fc6da1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Writing filtered and annotated substitutions to {output_csv}\")\n",
    "\n",
    "subs.to_csv(output_csv, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
